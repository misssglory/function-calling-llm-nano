# ğŸš€ Hybrid Search Agent with Step-by-Step Execution

---
Current README is primarily generated by AI with crucial adjustments about painless installation instructions
---

---
Contributors are welcome!
---

### Introduction
A powerful hybrid search agent that combines local document search, web search (DuckDuckGo), and web scraping (Playwright) with an innovative step-by-step execution mode. Perfect for complex research tasks, document analysis, and automated web interactions.

### [Colab example link with russian explanation](https://colab.research.google.com/drive/1BETnEIxmYr3Ttvfk5mBpCtFyFSqplods#scrollTo=FKYTn686B46W) ğŸ‡·ğŸ‡º


# âœ¨ Features
### ğŸ” Multi-Source Search
Local Document Search: Search through your PDFs, text files, and documents using vector embeddings

Web Search: DuckDuckGo integration for internet searches (no API key required)

Web Scraping: Full browser automation with Playwright for dynamic content

### ğŸ¯ Step-by-Step Execution
Automatic Task Decomposition: Complex queries are broken down into logical steps

Interactive Control: Approve, skip, or modify each step before execution

Execution History: Complete history of all steps with tool calls and results

Auto Mode: Toggle between manual and automatic execution

### ğŸ“¦ Model Management
Auto-download: Models are automatically downloaded on first use

Multiple Models: Support for various GGUF models (TinyLlama, Mistral, QVikhr, Saiga, etc.)

Smart Caching: Downloaded models are stored locally in ./models/

Model Selection: Choose models by simple names (e.g., tinyllama, qvikhr-3b)

### ğŸ› ï¸ Advanced Tools
Document Q&A: Semantic search over your documents

Web Navigation: Navigate to URLs, click elements, fill forms

Content Extraction: Extract text, hyperlinks, take screenshots, save as PDF

JavaScript Execution: Run custom JS on web pages

### ğŸ“Š Monitoring & Debugging
Phoenix Tracing: Full OpenTelemetry integration with Phoenix

Step History: JSON-formatted execution plans saved locally

Logging: Comprehensive logging with Loguru

Screenshots: Automatic screenshot capture during web interactions


---
# ğŸ—ï¸ Architecture
- Project statistics are lower
```
hybrid_search_agent/
â”œâ”€â”€ core/               # Core agent logic
â”‚   â”œâ”€â”€ hybrid_agent.py    # Main hybrid search agent
â”‚   â””â”€â”€ step_history.py    # Execution history management
â”œâ”€â”€ agents/            # Agent implementations
â”‚   â””â”€â”€ step_by_step_agent.py  # Step-by-step execution agent
â”œâ”€â”€ models/           # Data models
â”‚   â””â”€â”€ step_models.py      # Step and plan data structures
â”œâ”€â”€ sessions/         # Session management
â”‚   â””â”€â”€ interactive.py     # Interactive chat sessions
â”œâ”€â”€ utils/           # Utilities
â”‚   â”œâ”€â”€ model_utils.py     # Model download & management
â”‚   â”œâ”€â”€ display.py         # Console display helpers
â”‚   â”œâ”€â”€ setup.py          # Initialization utilities
â”‚   â””â”€â”€ tracing.py        # Tracing configuration
â””â”€â”€ config.py        # Configuration settings
```

---
# ğŸ“‹ Prerequisites
Python 3.12 or higher

4GB+ RAM (8GB+ recommended)

GPU optional but recommended for larger models

Internet connection for model downloads and web searches

---
# ğŸš€ Quick Start
### 1. Installation
```bash
# Clone the repository
git clone https://github.com/yourusername/hybrid-search-agent.git
cd hybrid-search-agent

# Create virtual environment
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate

# Install dependencies
CMAKE_ARGS="-DGGML_CUDA=on" FORCE_CMAKE=1  uv pip install -r requirements.txt --extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cu124 #--no-cache-dir --force-reinstall

# Install Playwright browsers
playwright install chromium
```
### 2. Basic usage
```python
import asyncio
from hybrid_search_agent.sessions.interactive import create_new_session, interactive_chat_session

async def main():
    # Create a session with TinyLlama (auto-downloads if not present)
    agent = await create_new_session(
        model="tinyllama",  # Model name or path
        step_by_step_mode=True,  # Enable step-by-step execution
        visible=True  # Show browser window
    )
    
    # Start interactive chat
    await interactive_chat_session(agent)

if __name__ == "__main__":
    asyncio.run(main())
```

### 3. Command line interface

```bash
# Run with step-by-step mode and visible browser
python run.py --step-by-step --visible --model tinyllama

# Quick query (non-interactive)
python run.py --model tinyllama --query "What is artificial intelligence?"

# List downloaded models
python run.py --list-models

# Download a specific model
python run.py --download qvikhr-3b

# Run with Russian model
python run.py --step-by-step --visible --model qvikhr-3b
```

### 4. Step-by-step mode demo
```
ğŸ¯ Your question: Find recent AI news and take a screenshot

ğŸ“‹ EXECUTION PLANNING
================================================================
ğŸ“Œ Step 1: Search for recent AI news using duckduckgo_search
ğŸ“Œ Step 2: Navigate to the first result URL
ğŸ“Œ Step 3: Extract text from the page
ğŸ“Œ Step 4: Take a screenshot of the page

âš¡ Executing: Search for recent AI news using duckduckgo_search
âœ… Step 1 completed successfully!
ğŸ“Š Result: Found 10 results about recent AI developments...

â¸ï¸ Step 1 completed. Continue? 
   [Enter] - continue
   [n] - next step
   [s] - skip step
   [a] - enable auto-execution
   [p] - show plan
```

# ğŸ¤– Available Models

## English Models ğŸ‡¬ğŸ‡§
- Key	Model	Size	Description
- tinyllama	TinyLlama 1.1B	0.7GB	Lightweight, fast
- llama2-7b	Llama 2 7B	4.1GB	Balanced performance
- mistral-7b	Mistral 7B	4.1GB	Excellent quality
- zephyr-7b	Zephyr 7B	4.1GB	Instruct-tuned
- phi-2	Phi-2 2.7B	1.6GB	Compact, capable

## Russian Models ğŸ‡·ğŸ‡º
- Key	Model	Size	Description
- qvikhr-3b	QVikhr 3.4B	2.1GB	Russian instruction model
- qvikhr-7b	QVikhr 7B	4.3GB	High-quality Russian model
- saiga-7b	Saiga 7B	4.1GB	Russian chatbot

# ğŸ“š Usage Examples

1. Local Document Search

```python
# Add documents to local index
await agent.add_document("./path/to/document.pdf")

# Search local documents
response = await agent.query("What information do we have about project X?")
```

2. Web Search with Screenshot

```python
# Step-by-step execution will show each phase
response = await agent.query_step_by_step(
    "Find information about climate change and save a screenshot of the top result"
)
```

3. Complex Multi-Step Task

```python
# Automatic decomposition into logical steps
async for event in agent.query_step_by_step(
    "Search for Python machine learning tutorials, open the top 3 results, "
    "extract the main content from each, and save them as PDFs"
):
    if event["type"] == "step_created":
        print(f"ğŸ“Œ New step: {event['step'].description}")
```

# âš™ï¸ Configuration

## Environment Variables (.env)

```bash
# Phoenix Tracing
PHOENIX_HOST=localhost
PHOENIX_PORT=6006
PHOENIX_ENABLED=true

# Model Settings
CONTEXT_WINDOW=6000
TEMPERATURE=0.1
MAX_NEW_TOKENS=1024
```

## Advanced Configuration

```python
agent = await create_new_session(
    model="mistral-7b",
    data_dir="./custom_data",  # Custom document directory
    persist_dir="./custom_storage",  # Custom index storage
    use_gpu=True,  # Enable GPU acceleration
    headless_browser=False,  # Show browser window
    playwright_slow_mo=100,  # Slow down operations (ms)
    step_by_step_mode=True,
    auto_download=True  # Auto-download missing models
)
```

# Project statistics
```python
â¯ python project_statistics.py __pycache__ data logs models pdfs screenshots step_history storage .venv .git
2026-02-14 07:31:34 - Analyzing path: .
2026-02-14 07:31:34 - Excluding folders: ['__pycache__', 'data', 'logs', 'models', 'pdfs', 'screenshots', 'step_history', 'storage', '.venv', '.git']
2026-02-14 07:31:34 - Excluding files: .json
2026-02-14 07:31:34 - Max bar length: 30 characters
2026-02-14 07:31:34 - Scanning directory: /home/mg/gh/function-calling-llm-nano
2026-02-14 07:31:35 - Found 30 files with 6261 total lines
2026-02-14 07:31:35 - Largest file: 968 lines

ğŸ“Š Project Line Count Statistics
======================================================================
Max bar length: 30 chars | Each 'â–ˆ' â‰ˆ 32.3 lines
======================================================================

ğŸ“ ./
â”œâ”€â”€ ğŸ—„ï¸ guard_composite.py               826 lines [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘]
â”œâ”€â”€ ğŸ“š tool_engines.py                  385 lines [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘]
â”œâ”€â”€ ğŸ“š project_statistics.py            262 lines [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘]
â”œâ”€â”€ ğŸ“š phoenix_client.py                255 lines [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘]
â”œâ”€â”€ ğŸ“š README.md                        251 lines [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘]
â”œâ”€â”€ ğŸ“š phoenix_server.py                205 lines [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘]
â”œâ”€â”€ ğŸ“„ guard.py                         172 lines [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘]
â”œâ”€â”€ ğŸ“„ run.py                           111 lines [â–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘]
â”œâ”€â”€ ğŸ“„ trace_context.py                  66 lines [â–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘]
â”œâ”€â”€ ğŸ”¸ LICENSE                           21 lines 
â”œâ”€â”€ ğŸ”¸ requirements.txt                  13 lines 
â””â”€â”€ ğŸ”¹ .gitignore                         2 lines 

ğŸ“ hybrid_search_agent/
â”œâ”€â”€ ğŸ“š config.py                        212 lines [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘]
â”œâ”€â”€ ğŸ“„ main.py                          145 lines [â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘]
â””â”€â”€ ğŸ”¸ init.py                           17 lines 

ğŸ“ hybrid_search_agent/agents/
â”œâ”€â”€ ğŸ—„ï¸ step_by_step_agent.py            968 lines [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ]
â””â”€â”€ ğŸ”¹ init.py                            5 lines 

ğŸ“ hybrid_search_agent/core/
â”œâ”€â”€ ğŸ—„ï¸ hybrid_agent.py                  551 lines [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘]
â”œâ”€â”€ ğŸ“„ step_history.py                  110 lines [â–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘]
â””â”€â”€ ğŸ”¹ init.py                            6 lines 

ğŸ“ hybrid_search_agent/sessions/
â”œâ”€â”€ ğŸ—„ï¸ interactive.py                   570 lines [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘]
â””â”€â”€ ğŸ”¹ init.py                            9 lines 

ğŸ“ hybrid_search_agent/utils/
â”œâ”€â”€ ğŸ“š model_utils.py                   348 lines [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘]
â”œâ”€â”€ ğŸ“š reduce_context.py                326 lines [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘]
â”œâ”€â”€ ğŸ“„ display.py                       162 lines [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘]
â”œâ”€â”€ ğŸ“„ string_processing.py             106 lines [â–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘]
â”œâ”€â”€ ğŸ“„ tracing.py                        54 lines [â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘]
â”œâ”€â”€ ğŸ”¸ setup.py                          45 lines [â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘]
â”œâ”€â”€ ğŸ”¸ validation.py                     37 lines [â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘]
â””â”€â”€ ğŸ”¸ init.py                           21 lines 

======================================================================
ğŸ“ˆ Total lines: 6261
ğŸ“ Total files: 30
ğŸ“Š Largest file: 968 lines

ğŸ“‹ Size Categories:
   ğŸ”¹ Tiny (<10 lines)    ğŸ”¸ Small (10-49 lines)    ğŸ“„ Medium (50-199 lines)
   ğŸ“š Large (200-499 lines)    ğŸ—„ï¸ Huge (500+ lines)
```